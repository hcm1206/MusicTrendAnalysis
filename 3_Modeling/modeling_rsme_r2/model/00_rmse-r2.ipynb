{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지 정리\n",
    "- 선형회귀 (32306492.502701458, -311072078793.17224)\n",
    "- 랜덤포레스트 (16.965335733586247, 0.9142159927901659)\n",
    "- xgboost (16.684195058044626, 0.91813965)\n",
    "- xgboost 학습률낮춤 (18.879495987572316, 0.893766347035579635935974)\n",
    "- LightGBM LightGBM RMSE: 16.90875747910959 LightGBM R²: 0.9147872065170526\n",
    "- 'SVR': {'RMSE': 56.65567382036248, 'R²': 0.043316616817139386},\n",
    "-  'KNN': {'RMSE': 41.70157881876481, 'R²': 0.4816937953779601},\n",
    "-  'Gradient Boosting': {'RMSE': 18.56903731139608, 'R²': 0.8972314591593191},\n",
    "- 'Neural Network': {'RMSE': 18.16043085324484, 'R²': 0.9017044836796914}\n",
    "- 결정트리 (23.304060333652917, 0.8381381109965736)\n",
    "\n",
    "- 'MLP': {'RMSE': 19.550403554924742, 'R²': 0.886081874370575},\n",
    "-  'LSTM': {'RMSE': 20.032270874855293, 'R²': 0.8803970813751221}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>date</th>\n",
       "      <th>New_Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Production</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Genre_split</th>\n",
       "      <th>season</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Weekly Views</th>\n",
       "      <th>...</th>\n",
       "      <th>Prod_YG Entertainment</th>\n",
       "      <th>Prod_YS Entertainment</th>\n",
       "      <th>Prod_Yoasobi</th>\n",
       "      <th>Prod_Yogurt Studio</th>\n",
       "      <th>Prod_Yogurt Studio, Danal Entertainment</th>\n",
       "      <th>Prod_Yuehua Entertainment Korea</th>\n",
       "      <th>Prod_Zero One Interactive</th>\n",
       "      <th>date_pi</th>\n",
       "      <th>weekly_count</th>\n",
       "      <th>cumulative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>악뮤</td>\n",
       "      <td>Love Lee</td>\n",
       "      <td>YG Entertainment</td>\n",
       "      <td>가요/댄스</td>\n",
       "      <td>['K-Pop', 'Dance']</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>-0.733963</td>\n",
       "      <td>2.119452</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.594157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>주호</td>\n",
       "      <td>내가 아니라도</td>\n",
       "      <td>IN A MILLION</td>\n",
       "      <td>가요/발라드</td>\n",
       "      <td>['K-Pop', 'Ballad']</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>1.052141</td>\n",
       "      <td>-1.011885</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.594157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>임영웅</td>\n",
       "      <td>London Boy</td>\n",
       "      <td>물고기뮤직</td>\n",
       "      <td>가요/락</td>\n",
       "      <td>['K-Pop', 'Rock']</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>0.947076</td>\n",
       "      <td>0.413551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.594157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>저스틴 비버</td>\n",
       "      <td>Off My Face</td>\n",
       "      <td>RBMG/Def Jam</td>\n",
       "      <td>POP/팝</td>\n",
       "      <td>['Pop', 'Pop']</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>-1.338086</td>\n",
       "      <td>-0.282185</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.594157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>윤하</td>\n",
       "      <td>오르트구름</td>\n",
       "      <td>C9엔터테인먼트</td>\n",
       "      <td>가요/락</td>\n",
       "      <td>['K-Pop', 'Rock']</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>-0.024775</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.594157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank        date New_Artist        Title        Production   Genre  \\\n",
       "0     1  2023-09-24         악뮤     Love Lee  YG Entertainment   가요/댄스   \n",
       "1   130  2023-09-24         주호      내가 아니라도      IN A MILLION  가요/발라드   \n",
       "2   131  2023-09-24        임영웅   London Boy             물고기뮤직    가요/락   \n",
       "3   132  2023-09-24     저스틴 비버  Off My Face      RBMG/Def Jam   POP/팝   \n",
       "4   133  2023-09-24         윤하        오르트구름          C9엔터테인먼트    가요/락   \n",
       "\n",
       "           Genre_split  season   Runtime  Weekly Views  ...  \\\n",
       "0   ['K-Pop', 'Dance']  Autumn -0.733963      2.119452  ...   \n",
       "1  ['K-Pop', 'Ballad']  Autumn  1.052141     -1.011885  ...   \n",
       "2    ['K-Pop', 'Rock']  Autumn  0.947076      0.413551  ...   \n",
       "3       ['Pop', 'Pop']  Autumn -1.338086     -0.282185  ...   \n",
       "4    ['K-Pop', 'Rock']  Autumn -0.024775      0.127099  ...   \n",
       "\n",
       "   Prod_YG Entertainment  Prod_YS Entertainment  Prod_Yoasobi  \\\n",
       "0                      1                      0             0   \n",
       "1                      0                      0             0   \n",
       "2                      0                      0             0   \n",
       "3                      0                      0             0   \n",
       "4                      0                      0             0   \n",
       "\n",
       "   Prod_Yogurt Studio  Prod_Yogurt Studio, Danal Entertainment  \\\n",
       "0                   0                                        0   \n",
       "1                   0                                        0   \n",
       "2                   0                                        0   \n",
       "3                   0                                        0   \n",
       "4                   0                                        0   \n",
       "\n",
       "   Prod_Yuehua Entertainment Korea  Prod_Zero One Interactive   date_pi  \\\n",
       "0                                0                          0  4.594157   \n",
       "1                                0                          0  4.594157   \n",
       "2                                0                          0  4.594157   \n",
       "3                                0                          0  4.594157   \n",
       "4                                0                          0  4.594157   \n",
       "\n",
       "   weekly_count  cumulative_count  \n",
       "0             1                 1  \n",
       "1             1                 1  \n",
       "2             1                 1  \n",
       "3             1                 1  \n",
       "4             1                 1  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV file\n",
    "file_path = '../dataset/01_total_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7874, 227), (1969, 227), (7874,), (1969,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 목표 변수는 'Rank'이고, 다른 컬럼들을 사용해 예측할 예정입니다.\n",
    "# 사용할 독립 변수를 선택하기 위해 먼저 데이터에서 숫자형 데이터만 추출합니다.\n",
    "numeric_data = data.select_dtypes(include='number')\n",
    "\n",
    "# X: 독립 변수, y: 종속 변수 (Rank)\n",
    "X = numeric_data.drop(columns=['Rank'])\n",
    "y = numeric_data['Rank']\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 나눕니다. 보통 80:20 비율로 나눔.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 나눈 데이터의 크기를 출력해 확인합니다.\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32306492.502701458, -311072078793.17224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 선형 회귀 모델 초기화 및 훈련\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# R^2 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.965335733586247, 0.9142159927901659)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 랜덤 포레스트 회귀 모델 초기화\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 훈련 세트로 모델 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에 대한 예측\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# RMSE와 R^2 계산\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "rmse_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.684195058044626, 0.9170355796813965)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 훈련 세트로 모델 학습\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에 대한 예측\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# RMSE와 R^2 계산\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "rmse_xgb, r2_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.879495987572316, 0.8937663435935974)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost 모델 하이퍼파라미터 조정 (n_estimators, max_depth, learning_rate, subsample)\n",
    "xgb_model_optimized = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, subsample=0.8, random_state=42)\n",
    "\n",
    "# 훈련 세트로 모델 학습\n",
    "xgb_model_optimized.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에 대한 예측\n",
    "y_pred_xgb_opt = xgb_model_optimized.predict(X_test)\n",
    "\n",
    "# RMSE와 R^2 계산\n",
    "rmse_xgb_opt = np.sqrt(mean_squared_error(y_test, y_pred_xgb_opt))\n",
    "r2_xgb_opt = r2_score(y_test, y_pred_xgb_opt)\n",
    "\n",
    "rmse_xgb_opt, r2_xgb_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 7874, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 99.695072\n",
      "LightGBM RMSE: 16.90875747910959\n",
      "LightGBM R²: 0.9147872065170526\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 피처 이름을 사용하지 않기 위해 DataFrame을 넘파이 배열로 변환\n",
    "X_train_np = X_train.values\n",
    "X_test_np = X_test.values\n",
    "\n",
    "# LightGBM 모델 초기화 및 학습\n",
    "lgbm_model = LGBMRegressor(random_state=42)\n",
    "lgbm_model.fit(X_train_np, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_np)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"LightGBM RMSE: {rmse_lgbm}\")\n",
    "print(f\"LightGBM R²: {r2_lgbm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nav_p\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SVR': {'RMSE': 56.65567382036248, 'R²': 0.043316616817139386},\n",
       " 'KNN': {'RMSE': 41.70157881876481, 'R²': 0.4816937953779601},\n",
       " 'Gradient Boosting': {'RMSE': 18.56903731139608, 'R²': 0.8972314591593191},\n",
       " 'Neural Network': {'RMSE': 18.16043085324484, 'R²': 0.9017044836796914}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다시 모델 초기화 및 학습 진행\n",
    "svr_model = SVR()\n",
    "knn_model = KNeighborsRegressor()\n",
    "gbr_model = GradientBoostingRegressor(random_state=42)\n",
    "mlp_model = MLPRegressor(random_state=42)\n",
    "\n",
    "# LightGBM 제외한 나머지 모델들을 리스트에 저장\n",
    "models_without_lgbm = {\n",
    "    \"SVR\": svr_model,\n",
    "    \"KNN\": knn_model,\n",
    "    \"Gradient Boosting\": gbr_model,\n",
    "    \"Neural Network\": mlp_model\n",
    "}\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "results_without_lgbm = {}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for name, model in models_without_lgbm.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # RMSE와 R^2 계산\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # 결과 저장\n",
    "    results_without_lgbm[name] = {\"RMSE\": rmse, \"R²\": r2}\n",
    "\n",
    "# 결과 출력\n",
    "results_without_lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.304060333652917, 0.8381381109965736)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 결정 트리 모델 초기화 및 학습\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에 대한 예측\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# RMSE와 R^2 계산\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "# 결과 출력\n",
    "rmse_dt, r2_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 아래로 ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nav_p\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nav_p\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MLP': {'RMSE': 19.550403554924742, 'R²': 0.886081874370575},\n",
       " 'LSTM': {'RMSE': 20.032270874855293, 'R²': 0.8803970813751221}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# 데이터 전처리: 표준화 (MLP, LSTM을 위해)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# MLP 모델 구축\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "mlp_model.add(Dense(64, activation='relu'))\n",
    "mlp_model.add(Dense(32, activation='relu'))\n",
    "mlp_model.add(Dense(1))  # 회귀 문제이므로 마지막 출력은 1개\n",
    "\n",
    "# MLP 모델 컴파일\n",
    "mlp_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# MLP 모델 학습\n",
    "mlp_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# MLP 예측 및 평가\n",
    "y_pred_mlp = mlp_model.predict(X_test_scaled)\n",
    "rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
    "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "# LSTM 모델을 위한 데이터 변환 (3차원으로 변환)\n",
    "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# LSTM 모델 구축\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "# LSTM 모델 컴파일\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# LSTM 모델 학습\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# LSTM 예측 및 평가\n",
    "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test, y_pred_lstm))\n",
    "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
    "\n",
    "# MLP와 LSTM 결과 출력\n",
    "{\n",
    "    'MLP': {'RMSE': rmse_mlp, 'R²': r2_mlp},\n",
    "    'LSTM': {'RMSE': rmse_lstm, 'R²': r2_lstm}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 전처리 (MinMaxScaler 사용)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # X_train 데이터를 0과 1 사이로 스케일링\n",
    "X_test_scaled = scaler.transform(X_test)        # X_test 데이터를 동일한 스케일로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 3차원으로 변환 (LSTM 모델을 위해)\n",
    "X_train_seq = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_seq = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# LSTM 모델 정의\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, activation='relu', input_shape=(X_train.shape[1], 1), kernel_initializer='glorot_uniform'))  # LSTM 레이어\n",
    "    model.add(Dropout(0.2))  # 과적합 방지를 위한 Dropout 레이어\n",
    "    model.add(Dense(1))  # 회귀 문제이므로 출력 노드는 1개\n",
    "    # Adam 옵티마이저 설정 (학습률 낮춤, 그라디언트 클리핑 추가)\n",
    "    adam = Adam(learning_rate=0.0001, clipvalue=1.0)\n",
    "    model.compile(optimizer=adam, loss='mse')  # MSE 손실 함수 사용\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)  # 모델 학습\n",
    "    y_pred = model.predict(X_test)  # 예측 값 계산\n",
    "    print(f\"NaN in predictions: {np.isnan(y_pred).sum()}\")  # 예측 값에 NaN이 있는지 확인\n",
    "    if np.isnan(y_pred).sum() > 0:  # NaN 값이 있으면 평가 건너뜀\n",
    "        print(\"NaN values detected in predictions. Skipping evaluation.\")\n",
    "        return None, None\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # RMSE 계산\n",
    "    r2 = r2_score(y_test, y_pred)  # R² 계산\n",
    "    return rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nav_p\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - loss: nan   \n",
      "Epoch 2/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 58ms/step - loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: nan\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "NaN in predictions: 1969\n",
      "NaN values detected in predictions. Skipping evaluation.\n",
      "LSTM model could not be evaluated due to NaN values in predictions.\n"
     ]
    }
   ],
   "source": [
    "# LSTM 학습 및 평가\n",
    "lstm_model = build_lstm()\n",
    "rmse_lstm, r2_lstm = evaluate_model(lstm_model, X_train_seq, y_train, X_test_seq, y_test)\n",
    "\n",
    "# 결과 출력\n",
    "if rmse_lstm is not None and r2_lstm is not None:\n",
    "    print(f\"LSTM RMSE: {rmse_lstm}, R²: {r2_lstm}\")\n",
    "else:\n",
    "    print(\"LSTM model could not be evaluated due to NaN values in predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
